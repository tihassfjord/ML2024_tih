{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive plot function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plotly\n",
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmpl_toolkits\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmplot3d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Axes3D\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objects\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_3d_data\u001b[39m(x_data, y_data, z_data, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, interactive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    A function to plot 3D data interactively or statically.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    - interactive: If True, uses Plotly for interactive 3D plots. If False, uses Matplotlib for static plots.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_3d_data(x_data, y_data, z_data, title=\"\", interactive=False):\n",
    "    \"\"\"\n",
    "    A function to plot 3D data interactively or statically.\n",
    "    \n",
    "    Parameters:\n",
    "    - x_data: Data for the x-axis\n",
    "    - y_data: Data for the y-axis\n",
    "    - z_data: Data for the z-axis (e.g., sigmoid outputs)\n",
    "    - title: Title for the plot\n",
    "    - interactive: If True, uses Plotly for interactive 3D plots. If False, uses Matplotlib for static plots.\n",
    "    \"\"\"\n",
    "    if interactive:\n",
    "        # Use Plotly for an interactive 3D plot\n",
    "        fig = go.Figure(data=[go.Scatter3d(x=x_data, y=y_data, z=z_data, mode='markers', marker=dict(size=5))])\n",
    "        fig.update_layout(title=title, scene=dict(xaxis_title='X-axis', yaxis_title='Y-axis', zaxis_title='Z-axis'),\n",
    "                          autosize=False, width=800, height=600, margin=dict(l=0, r=0, b=0, t=40))\n",
    "        fig.show()\n",
    "    else:\n",
    "        # Use Matplotlib for a static 3D plot\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(x_data, y_data, z_data, color='blue', s=50, alpha=0.8)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('X-axis')\n",
    "        ax.set_ylabel('Y-axis')\n",
    "        ax.set_zlabel('Z-axis')\n",
    "        plt.show()\n",
    "\n",
    "# Example Usage\n",
    "x_data = [1, 2, 3, 4, 5]  # Replace with your x-axis data\n",
    "y_data = [2, 3, 4, 5, 6]  # Replace with your y-axis data\n",
    "z_data = [1.2, 3.1, 5.0, 7.5, 9.0]  # Replace with your z-axis data\n",
    "\n",
    "# Call the function with interactive=False for a static plot\n",
    "plot_3d_data(x_data, y_data, z_data, title=\"Static 3D Plot\", interactive=False)\n",
    "\n",
    "# Call the function with interactive=True for an interactive plot\n",
    "plot_3d_data(x_data, y_data, z_data, title=\"Interactive 3D Plot\", interactive=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mpl_toolkits.mplot3d import Axes3D  # For 3D plotting\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# (1a) Generate bivariate instances from two normal distributions\n",
    "mu1 = np.array([0, 0])  # Mean of the first class\n",
    "mu2 = np.array([1, 1])  # Mean of the second class\n",
    "sigma1 = np.eye(2)  # Identity covariance matrix for class 1\n",
    "sigma2 = np.eye(2)  # Identity covariance matrix for class 2\n",
    "\n",
    "# Generate 5 samples from each distribution\n",
    "np.random.seed(42)  # Seed for reproducibility\n",
    "samples1 = np.random.multivariate_normal(mu1, sigma1, 5)  # Class 1 samples\n",
    "samples2 = np.random.multivariate_normal(mu2, sigma2, 5)  # Class 2 samples\n",
    "\n",
    "# Combine the data\n",
    "X = np.concatenate((samples1, samples2), axis=0)\n",
    "y = np.concatenate((np.zeros(5), np.ones(5)))  # Class labels (0 for class 1, 1 for class 2)\n",
    "\n",
    "# (1b) Train logistic regression model using scikit-learn\n",
    "logreg = LogisticRegression(solver='lbfgs')\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# Get the learned weights and intercept\n",
    "weights = logreg.coef_[0]  # Coefficients (weights)\n",
    "intercept = logreg.intercept_[0]  # Intercept (bias)\n",
    "\n",
    "# Function to calculate the decision boundary line\n",
    "def decision_boundary(x1, weights, intercept):\n",
    "    w1, w2 = weights  # Extract weights for x1 and x2\n",
    "    return -(w1 / w2) * x1 - (intercept / w2)  # Rearrange to get x2 in terms of x1\n",
    "\n",
    "# Generate x1 values for plotting, make sure it covers the entire x-axis range of the data\n",
    "x1_range = np.linspace(X[:, 0].min(), X[:, 0].max(), 100)\n",
    "x2_range = decision_boundary(x1_range, weights, intercept)\n",
    "\n",
    "# Plot the 2D samples\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(samples1[:, 0], samples1[:, 1], color='red', label='Class 1 (μ1)')\n",
    "plt.scatter(samples2[:, 0], samples2[:, 1], color='blue', label='Class 2 (μ2)')\n",
    "\n",
    "# Plot the learned decision boundary\n",
    "plt.plot(x1_range, x2_range, color='green', label='Learned Decision Boundary')\n",
    "plt.axhline(0, color='black', linewidth=0.5)\n",
    "plt.axvline(0, color='black', linewidth=0.5)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('Bivariate Instances of Class 1 and Class 2 with Decision Boundary')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# (1b) Transform to 3D space with sigmoid output as z-axis\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Calculate sigmoid outputs for plotting\n",
    "z1 = sigmoid(np.dot(samples1, weights) + intercept)\n",
    "z2 = sigmoid(np.dot(samples2, weights) + intercept)\n",
    "\n",
    "# Plot the samples in 3D\n",
    "ax.scatter(samples1[:, 0], samples1[:, 1], z1, color='red', label='Class 1 (μ1)')\n",
    "ax.scatter(samples2[:, 0], samples2[:, 1], z2, color='blue', label='Class 2 (μ2)')\n",
    "\n",
    "# Plot the decision boundary surface\n",
    "x_vals = np.linspace(-2, 2, 100)\n",
    "y_vals = np.linspace(-2, 2, 100)\n",
    "X_grid, Y_grid = np.meshgrid(x_vals, y_vals)\n",
    "Z_grid = sigmoid(weights[0] * X_grid + weights[1] * Y_grid + intercept)\n",
    "ax.plot_surface(X_grid, Y_grid, Z_grid, color='green', alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_zlabel('Sigmoid Output')\n",
    "ax.set_title('3D Plot: Sigmoid Output and Logistic Decision Boundary')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# (1c) Ineffective decision boundary (random weights and bias)\n",
    "ineffective_weights = np.array([0.1, -0.2])  # Arbitrary ineffective weights\n",
    "ineffective_intercept = 0.5  # Arbitrary ineffective bias\n",
    "\n",
    "# 3D plot of ineffective decision boundary\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Ineffective decision boundary sigmoid output\n",
    "z1_ineff = sigmoid(np.dot(samples1, ineffective_weights) + ineffective_intercept)\n",
    "z2_ineff = sigmoid(np.dot(samples2, ineffective_weights) + ineffective_intercept)\n",
    "\n",
    "# Plot ineffective samples in 3D\n",
    "ax.scatter(samples1[:, 0], samples1[:, 1], z1_ineff, color='red', label='Class 1 (μ1)')\n",
    "ax.scatter(samples2[:, 0], samples2[:, 1], z2_ineff, color='blue', label='Class 2 (μ2)')\n",
    "\n",
    "# Ineffective decision boundary surface\n",
    "Z_grid_ineff = sigmoid(ineffective_weights[0] * X_grid + ineffective_weights[1] * Y_grid + ineffective_intercept)\n",
    "ax.plot_surface(X_grid, Y_grid, Z_grid_ineff, color='green', alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "ax.set_zlabel('Sigmoid Output')\n",
    "ax.set_title('Ineffective Decision Boundary (~50% Accuracy)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# (1d) Loss Function\n",
    "# The appropriate loss function for logistic regression is binary cross-entropy, also known as log loss.\n",
    "# This loss function measures how well the model's predicted probabilities match the true labels.\n",
    "\n",
    "# (1e) Neuron and Logistic Regression\n",
    "# Logistic regression closely resembles a single neuron in a neural network:\n",
    "# - The input features (X1, X2) are weighted sums (w1 * X1 + w2 * X2) with a bias term.\n",
    "# - The result of this linear combination is passed through an activation function (sigmoid) to produce the final output.\n",
    "# - The sigmoid function in both logistic regression and neural networks maps the output to the range (0, 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
